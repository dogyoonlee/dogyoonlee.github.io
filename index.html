<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dogyoon Lee</title>
  
  <meta name="author" content="Dogyoon Lee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dogyoon Lee</name>
              </p>
              <p>
                I am Ph.D candidate at <a href="https://www.yonsei.ac.kr">Yonsei University</a> in <a href="https://en.wikipedia.org/wiki/Seoul">Seoul</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                My research mainly focuses on various 3D computer vision tasks using images and point cloud. Recent research field is related to neural rendering and its applications. 
              </p>
              <p>
                I'm always open to collaborations or suggestions. Please feel free to contact me if you have any questions or suggestions. :)
              </p>
              <!-- <p>
                I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:dogyoonlee@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/resume/dogyoonlee-resume.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/resume/dogyoonlee-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=ww2vWOcAAAAJ&hl=ko">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/dogyoonlee/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/dogyoonlee.png">
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publication</heading>
              <!-- <p> -->
                <!-- I'm interested in 2D/3D computer vision, graphics, and machine learning. Recent research topic is mainly related to neural rendering with various conditions. Representative papers are <span class="highlight">highlighted</span>. -->
              <!-- </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
<!-- 
<tr onmouseout="dpnerf_stop()" onmouseover="dpnerf_start()"  bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='dpnerf_image'><video  width=100% height=100% muted autoplay loop>
      <source src="images/dpnerf/dpnerf_video.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='images/dpnerf/dpnerf_image.png' width="160">
    </div>
    <script type="text/javascript">
      function dpnerf_start() {
        document.getElementById('dpnerf_image').style.opacity = "1";
      }

      function dpnerf_stop() {
        document.getElementById('dpnerf_image').style.opacity = "0";
      }
      dpnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">
      <papertitle>DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors</papertitle>
    </a>
    <br>
    <strong>Dogyoon Lee</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=flyFxPsAAAAJ&hl=ko&oi=ao">Chajin Shin</a>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2023 
    <br>
    <a href="https://dogyoonlee.github.io/dpnerf">Project page</a>
    /
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/DP-NeRF">Code</a>
    /
    <a href="data/bib/dpnerf2023.txt">bib</a>
    <p></p>
    <p>
    We impose the physical constraints on the blurring kernel of neural radiance field to construct clean neural radiance field from blurry images.
    </p>
  </td>
</tr> -->

<tr onmouseout="pcvr_stop()" onmouseover="pcvr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='pcvr_image'>
        <img src='images/pcvr/pcvr_after.png' width="160">
      </div>
      <img src='images/pcvr/pcvr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function pcvr_start() {
        document.getElementById('pcvr_image').style.opacity = "1";
      }

      function pcvr_stop() {
        document.getElementById('pcvr_image').style.opacity = "0";
      }
      pcvr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf"> -->
      <papertitle>ProDepth: Boosting Self-Supervised Multi-Frame Monocular Depth with Probabilistic Fusion</papertitle>
    <!-- </a> -->
    <br>
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko">Sungmin Woo*</a>,
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko">Wonjoon Lee*</a>,
    <a href="https://scholar.google.com/citations?user=hDyC0w0AAAAJ&hl=ko">Woojin Kim</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>European Conference on Computer Vision (ECCV) </em>, 2024 
    <br>
    <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/SVL">Code</a>
    /
    <a href="data/bib/svl2024.txt">bib</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose novel cost volume refinement model for self-supervised multi-frame monocular depth estimation model.
    </p>
  </td>
</tr>

<tr onmouseout="gsa_stop()" onmouseover="gsa_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='gsa_image'>
        <img src='images/gsa/slot_attention_after.png' width="160">
      </div>
      <img src='images/gsa/slot_attention_before.png' width="160">
    </div>
    <script type="text/javascript">
      function gsa_start() {
        document.getElementById('gsa_image').style.opacity = "1";
      }

      function gsa_stop() {
        document.getElementById('gsa_image').style.opacity = "0";
      }
      gsa_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2303.08314.pdf">
      <papertitle>Guided Slot Attention for Unsupervised Video Object Segmentation</papertitle>
    </a>
    <br>
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=OskGL0sAAAAJ&hl=ko&oi=ao">Chaewon Park</a>,
    <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2024 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Lee_Guided_Slot_Attention_for_Unsupervised_Video_Object_Segmentation_CVPR_2024_paper.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/GSANet?tab=readme-ov-file">Code</a>
    /
    <a href="data/bib/gsa_2024.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a guided slot attention network to reinforce spatial structural information and obtain better foreground‚Äìbackground separation.
    </p>
  </td>
</tr>
  

<tr onmouseout="dpa_stop()" onmouseover="dpa_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='dpa_image'>
        <img src='images/dpa/dpa_after.png' width="160">
      </div>
      <img src='images/dpa/dpa_before.png' width="160">
    </div>
    <script type="text/javascript">
      function dpa_start() {
        document.getElementById('dpa_image').style.opacity = "1";
      }

      function dpa_stop() {
        document.getElementById('dpa_image').style.opacity = "0";
      }
      dpa_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2211.12036.pdf">
      <papertitle>Dual Prototype Attention for Unsupervised Video Object Segmentation</papertitle>
    </a>
    <br>
    <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://github.com/iseunghoon">Seunghoon Lee</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2024 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Cho_Dual_Prototype_Attention_for_Unsupervised_Video_Object_Segmentation_CVPR_2024_paper.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/DATA">Code</a>
    /
    <a href="data/bib/dpa2024.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose two novel prototype-based attention mechanisms to incorporate different modalities and frames via dense propagation across them.
    </p>
  </td>
</tr>


<tr onmouseout="dpnerf_stop()" onmouseover="dpnerf_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='dpnerf_image'>
        <img src='images/dpnerf/dpnerf_after.png' width="160"></div>
      <img src='images/dpnerf/dpnerf_before.png' width="160">
    </div>
    <script type="text/javascript">
      function dpnerf_start() {
        document.getElementById('dpnerf_image').style.opacity = "1";
      }

      function dpnerf_stop() {
        document.getElementById('dpnerf_image').style.opacity = "0";
      }
      dpnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">
      <papertitle>DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors</papertitle>
    </a>
    <br>
    <strong>Dogyoon Lee</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=flyFxPsAAAAJ&hl=ko&oi=ao">Chajin Shin</a>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2023 
    <br>
    <a href="https://dogyoonlee.github.io/dpnerf">Project Page</a>
    /
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.html">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/DP-NeRF">Code</a>
    /
    <a href="data/bib/dpnerf2023.txt">bib</a>
    <p></p>
    <p>
    We impose the physical constraints on the blurring kernel of neural radiance field to construct clean neural radiance field from blurry images.
    </p>
  </td>
</tr>
          
<tr onmouseout="hdgcn_stop()" onmouseover="hdgcn_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='hdgcn_image'>
        <img src='images/hdgcn/hdgcn_after.png' width="160"></div>
      <img src='images/hdgcn/hdgcn_before.png' width="160">
    </div>
    <script type="text/javascript">
      function hdgcn_start() {
        document.getElementById('hdgcn_image').style.opacity = "1";
      }

      function hdgcn_stop() {
        document.getElementById('hdgcn_image').style.opacity = "0";
      }
      hdgcn_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2208.10741.pdf">
      <papertitle>Hierarchically Decomposed Graph Convolutional Networks for Skeleton- Based Action Recognition</papertitle>
    </a>
    <br>
    <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 
    <br>
    <a href="https://arxiv.org/pdf/2208.10741.pdf">Paper</a>
    /
    <a href="https://github.com/Jho-Yonsei/HD-GCN">Code</a>
    /
    <a href="data/bib/hdgcn2023.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a hierarchically decomposed graph convolution with a novel hierarchically decomposed graph, which consider the sematic correlation between the joints and the edges of the human skeleton.
    </p>
  </td>
</tr>


<tr onmouseout="tsa_stop()" onmouseover="tsa_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tsa_image'>
        <img src='images/tsa/tsa_after.png' width="160"></div>
      <img src='images/tsa/tsa_before.png' width="160">
    </div>
    <script type="text/javascript">
      function tsa_start() {
        document.getElementById('tsa_image').style.opacity = "1";
      }

      function tsa_stop() {
        document.getElementById('tsa_image').style.opacity = "0";
      }
      tsa_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2303.04376.pdf">
      <papertitle>TSANET: Temporal and Scale Alignment for Unsupervised Video Object Segmentation</papertitle>
    </a>
    <br>
    <a href="https://github.com/iseunghoon">Seunghoon Lee</a>,
    <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2023
    <br>
    <a href="https://arxiv.org/pdf/2303.04376.pdf">Paper</a>
    /
    <!-- <a href="https://">Code</a> -->
    <!-- / -->
    <a href="data/bib/tsa2023.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel framework for unsupervised video object segmentation, which can utilize both contextual and motion information from adjacent frames, introducing a temporal and scale alignment network (TSANet).
    </p>
  </td>
</tr>

<tr onmouseout="mkconv_stop()" onmouseover="mkconv_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='mkconv_image'>
        <img src='images/mkconv/mkconv_after.png' width="160"></div>
      <img src='images/mkconv/mkconv_before.png' width="160">
    </div>
    <script type="text/javascript">
      function mkconv_start() {
        document.getElementById('mkconv_image').style.opacity = "1";
      }

      function mkconv_stop() {
        document.getElementById('mkconv_image').style.opacity = "0";
      }
      mkconv_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4332140">
      <papertitle>Mkconv: Multidimensional Feature Representation for Point Cloud Analysis</papertitle>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko">Sungmin Woo</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=OgE2y40AAAAJ&hl=ko">Sangwon Hwang</a>,
    <a href="https://scholar.google.com/citations?user=hDyC0w0AAAAJ&hl=ko">Woojin Kim</a>,
    <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>Pattern Recognition (PR)</em>, 2023
    <br>
    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4332140">Paper</a>
    <!-- / -->
    <!-- <a href="https://">Code</a> -->
    /
    <a href="data/bib/mkconv2023.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel framework for point cloud processing, which can utilize both local and global information from point clouds, introducing a multidimensional feature representation (Mkconv).
    </p>
  </td>
</tr>

<tr onmouseout="easn_stop()" onmouseover="easn_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='easn_image'>
        <img src='images/easn/easn_after.png' width="160"></div>
      <img src='images/easn/easn_before.png' width="160">
    </div>
    <script type="text/javascript">
      function easn_start() {
        document.getElementById('easn_image').style.opacity = "1";
      }

      function easn_stop() {
        document.getElementById('easn_image').style.opacity = "0";
      }
      easn_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136770392.pdf">
      <papertitle>Expanded Adaptive Scaling Normalization for End-to-End Image Compression</papertitle>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=flyFxPsAAAAJ&hl=ko&oi=ao">Chajin Shin</a>,
    <a href="http://hyeongminlee.github.io">Hyeongmin Lee</a>,
    <a href="https://scholar.google.com/citations?user=PuId8x8AAAAJ&hl=ko&oi=aor">Hanbin Son</a>,
    <a href="https://scholar.google.com/citations?user=W0TdF-EAAAAJ&hl=ko&oi=sra">Sangjin Lee</a>,
    <strong>Dogyoon Lee</strong>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>European Conference on Computer Vision (ECCV)</em>, 2022 
    <br>
    <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136770392.pdf">Paper</a>
    /
    <a href="https://github.com/ChajinShin/EASN">Code</a>
    /
    <a href="data/bib/easn2022.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose rescaling module for the image compression network which is enhanced version of existing GDN with higher degree of freedom.
    </p>
  </td>
</tr>

<tr onmouseout="robustlane_stop()" onmouseover="robustlane_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='robust_lane_image'>
        <img src='images/robust_lane/lane_after.png' width="160"></div>
      <img src='images/robust_lane/lane_before.png' width="160">
    </div>
    <script type="text/javascript">
      function robustlane_start() {
        document.getElementById('robust_lane_image').style.opacity = "1";
      }

      function robustlane_stop() {
        document.getElementById('robust_lane_image').style.opacity = "0";
      }
      robustlane_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2102.07037.pdf">
      <papertitle>Robust Lane Detection via Expanded Self attention</papertitle>
    </a>
    <br>
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=1b4K9wsAAAAJ&hl=ko&oi=ao">Junhyeop Lee</a>,
    <strong>Dogyoon Lee</strong>,
    <a href="https://scholar.google.com/citations?user=hDyC0w0AAAAJ&hl=ko&oi=sra">Woojin Kim</a>,
    <a href="https://scholar.google.com/citations?user=OgE2y40AAAAJ&hl=ko&oi=ao">Sangwon Hwang</a>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2022 
    <br>
    <a href="https://arxiv.org/pdf/2102.07037.pdf">Paper</a>
    /
    <a href="https://github.com/Hydragon516/ESA-official">Code</a>
    /
    <a href="data/bib/robustlane2022.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel self-attention module called the Expanded Self Attention for lane detection in autonomous vehicle to be robust in challenging situations.
    </p>
  </td>
</tr>

<tr onmouseout="rsmix_stop()" onmouseover="rsmix_start()"   bgcolor="#ffffd0">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='rsmix_image'>
        <img src='images/rsmix/rsmix_after.png' width="160"></div>
      <img src='images/rsmix/rsmix_before.png' width="160">
    </div>
    <script type="text/javascript">
      function rsmix_start() {
        document.getElementById('rsmix_image').style.opacity = "1";
      }

      function rsmix_stop() {
        document.getElementById('rsmix_image').style.opacity = "0";
      }
      rsmix_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">
      <papertitle>Regularization Strategy for Point Cloud via Rigidly Mixed Sample</papertitle>
    </a>
    <br>
    <strong>Dogyoon Lee</strong>,
    Jaeha Lee,
    <a href="https://scholar.google.com/citations?user=1b4K9wsAAAAJ&hl=ko&oi=ao">Junhyeop Lee</a>,
    <a href="http://hyeongminlee.github.io">Hyeongmin Lee</a>,
    <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko&oi=ao">Sungmin Woo</a>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em>, 2021 
    <br>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.pdf">Paper</a>
    /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a>
    /
    <a href="data/bib/rsmix2021.txt">bib</a>
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel data augmentation method called Rigid Subset Mix (RSMix) which generates virtual mixed samples by replacing part of the sample with shape-preserved subsets from another sample.
    </p>
  </td>
</tr>

<tr onmouseout="fpr_stop()" onmouseover="fpr_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='fpr_image'>
        <img src='images/fpr/fpr_after.png' width="160"></div>
      <img src='images/fpr/fpr_before.png' width="160">
    </div>
    <script type="text/javascript">
      function fpr_start() {
        document.getElementById('fpr_image').style.opacity = "1";
      }

      function fpr_stop() {
        document.getElementById('fpr_image').style.opacity = "0";
      }
      fpr_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <!-- <a href="https://dreamfusion3d.github.io/"> -->
    <a href="https://arxiv.org/pdf/2005.13153.pdf">
      <papertitle>False Positive Removal For 3D Vehicle Detection with Penetrated Point Classifier</papertitle>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=q1BRGh0AAAAJ&hl=ko&oi=ao">Sungmin Woo</a>,
    <a href="https://scholar.google.com/citations?user=OgE2y40AAAAJ&hl=ko&oi=ao">Sangwon Hwang</a>,
    <a href="https://scholar.google.com/citations?user=hDyC0w0AAAAJ&hl=ko&oi=sra">Woojin Kim</a>,
    <a href="https://scholar.google.com/citations?user=1b4K9wsAAAAJ&hl=ko&oi=ao">Junhyeop Lee</a>,
    <strong>Dogyoon Lee</strong>,
		<a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
    <br>
    <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
    <em>IEEE International Conference on Image Processing (ICIP)</em>, 2020
    <br>
    <a href="https://arxiv.org/pdf/2005.13153.pdf">Paper</a>
    /
    <a href="data/bib/fpr2020.txt">bib</a>
    <!-- /
    <a href="https://github.com/dogyoonlee/RSMix">Code</a> -->
    <!-- /
    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
    <p></p>
    <p>
    <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
    We propose a novel post-processing method to remove false positives in 3D vehicle detection utilizing the characteristics of the LiDAR censor itself.
    </p>
  </td>
</tr>

</tbody></table>

				
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Preprint</heading>
        </td>
      </tr>
    </tbody>
  </table>
  
  
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>


      <!-- <tr onmouseout="glcod_stop()" onmouseover="glcod_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='gl_cod_image'>
              <img src='images/gl_cod/gl_cod_after.png' width="160">
            </div>
            <img src='images/gl_cod/gl_cod_before.png' width="160">
          </div>
          <script type="text/javascript">
            function glcod_start() {
              document.getElementById('gl_cod_image').style.opacity = "1";
            }
        
            function glcod_stop() {
              document.getElementById('gl_cod_image').style.opacity = "0";
            }
            glcod_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2211.12048.pdf">
            <papertitle>Global-Local Aggregation with Deformable Point Sampling for Camouflaged Object Detection</papertitle>
          </a>
          <br>
          <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
          <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
          <a href="https://scholar.google.com/citations?user=OskGL0sAAAAJ&hl=ko&oi=ao">Chaewon Park</a>,
          <strong>Dogyoon Lee</strong>,
          <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
          <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
          <br>
          <em>Pending</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2211.12048.pdf">Paper</a>
          /
          <a href="https://hydragon.co.kr/">Code</a>
          /
          <a href="data/bib/gl_cod2023.txt">bib</a>
          <p></p>
          <p>
          We propose novel deformable point sampling method and global-local aggregation architecture to integrate object's global information, background, and boundary local information to improve the camouflaged object detection.
          </p>
        </td>
      </tr> -->
        

      <tr onmouseout="svl_stop()" onmouseover="svl_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='svl_image'>
              <img src='images/svl/svl_after.png' width="160">
            </div>
            <img src='images/svl/svl_before.png' width="160">
          </div>
          <script type="text/javascript">
            function svl_start() {
              document.getElementById('svl_image').style.opacity = "1";
            }
      
            function svl_stop() {
              document.getElementById('svl_image').style.opacity = "0";
            }
            svl_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <!-- <a href="https://dreamfusion3d.github.io/"> -->
          <a href="https://arxiv.org/pdf/2311.17952.pdf">
            <papertitle>Synchronizing Vision and Language: Bidirectional Token-Masking AutoEncoder for Referring Image Segmentation</papertitle>
          </a>
          <br>
          <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
          <strong>Dogyoon Lee</strong>,
          <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
          <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
          Heeseung Choi,
          Ig-jae Kim,
          <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
          <br>
          <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
          <em>Arxiv, Preprint, Pending</em>, 2024 
          <br>
          <a href="https://arxiv.org/pdf/2311.17952.pdf">Paper</a>
          /
          <a href="https://github.com/Hydragon516/SVL">Code</a>
          /
          <a href="data/bib/svl2024.txt">bib</a>
          <!-- /
          <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
          <p></p>
          <p>
          <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
          We propose novel bi-directional token-masking autoencoder (BTMAE) for referring image segmentation (RIS) to effectively utilize contextual information between language and visual features.
          </p>
        </td>
      </tr>
      

      <tr onmouseout="sparse_derf_stop()" onmouseover="sparse_derf_start()" >
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='sparse_derf_image'>
              <img src='images/sparse-derf/sparse-derf_after.png' width="160">
            </div>
            <img src='images/sparse-derf/sparse-derf_before.png' width="160">
          </div>
          <script type="text/javascript">
            function sparse_derf_start() {
              document.getElementById('sparse_derf_image').style.opacity = "1";
            }
      
            function sparse_derf_stop() {
              document.getElementById('sparse_derf_image').style.opacity = "0";
            }
            sparse_derf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <!-- <a href="https://dreamfusion3d.github.io/"> -->
          <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf"> -->
            <papertitle>Sparse-DeRF: Deblurred Neural Radiance Fields from Sparse View</papertitle>
          <!-- </a> -->
          <br>
          <strong>Dogyoon Lee</strong>,
          <a href="https://scholar.google.com/citations?user=BaFYtwgAAAAJ&hl=ko">Donghyeong Kim</a>,
          <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
          <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
          <a href="https://github.com/iseunghoon">Seunghoon Lee</a>,
          <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
          <br>
          <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
          <em>Pending</em>, 2024 
          <br>
          <a href="https://dogyoonlee.github.io/sparsederf">Project Page</a>
          /
          <a href="https://arxiv.org/">Paper</a>
          <!-- /
          <a href="https://github.com/dogyoonlee/Sparse-DeRF">Code</a>
          /
          <a href="data/bib/svl2024.txt">bib</a> -->
          <p></p>
          <p>
          <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
          We propose enhanced deblurred neural radiance fields from sparse view settings for more practical applications considering real-world scenarios.
          </p>
        </td>
      </tr>

      <tr onmouseout="smurf_stop()" onmouseover="smurf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='smurf_image'>
              <img src='images/smurf/smurf_after.png' width="160">
            </div>
            <img src='images/smurf/smurf_before.png' width="160">
          </div>
          <script type="text/javascript">
            function smurf_start() {
              document.getElementById('smurf_image').style.opacity = "1";
            }
      
            function smurf_stop() {
              document.getElementById('smurf_image').style.opacity = "0";
            }
            smurf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <!-- <a href="https://dreamfusion3d.github.io/"> -->
          <a href="https://arxiv.org/pdf/2403.07547.pdf">
            <papertitle>SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields</papertitle>
          </a>
          <br>
          <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
          <strong>Dogyoon Lee</strong>,
          <a href="https://hydragon.co.kr">Minhyeok Lee</a>,
          <a href="https://scholar.google.com/citations?user=BaFYtwgAAAAJ&hl=ko">Donghyeong Kim</a>
          <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
          <br>
          <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
          <em>Arxiv, Preprint, Pending</em>, 2024 
          <br>
          <a href="https://arxiv.org/pdf/2403.07547.pdf">Paper</a>
          /
          <a href="https://github.com/Jho-Yonsei/SMURF/">Code</a>
          /
          <a href="data/bib/smurf2024.txt">bib</a>
          <p></p>
          <p>
          We propose novel blur kernel for motion estimation based on neural ordinary differential function to construct the deblurred neural radiance fields.
          </p>
        </td>
      </tr>

      <tr onmouseout="crim_gs_stop()" onmouseover="crim_gs_start()" >
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='crim_gs_image'>
              <img src='images/crim-gs/crim-gs_after.png' width="160">
            </div>
            <img src='images/crim-gs/crim-gs_before.png' width="160">
          </div>
          <script type="text/javascript">
            function crim_gs_start() {
              document.getElementById('crim_gs_image').style.opacity = "1";
            }
      
            function crim_gs_stop() {
              document.getElementById('crim_gs_image').style.opacity = "0";
            }
            crim_gs_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <!-- <a href="https://dreamfusion3d.github.io/"> -->
          <!-- <a href="https://arxiv.org/pdf/2311.17952.pdf"> -->
            <papertitle>CRiM-GS: Continuous Rigid Motion-Aware Gaussian Splatting from Motion Blur Images</papertitle>
          <!-- </a> -->
          <br>
          <a href="https://jho-yonsei.github.io">Jungho Lee</a>,
          <a href="https://scholar.google.com/citations?user=BaFYtwgAAAAJ&hl=ko">Donghyeong Kim</a>,
          <strong>Dogyoon Lee</strong>,
          <a href="https://suhwan-cho.github.io">Suhwan Cho</a>,
          <a href="https://scholar.google.com/citations?user=b7A10VYAAAAJ&hl=ko&oi=ao">Sangyoun Lee</a>
          <br>
          <!-- <em>Preprint</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
          <em>Pending</em>, 2024 
          <br>
          <a href="https://jho-yonsei.github.io/CRiM-Gaussian/">Project Page</a>
          /
          <a href="https://arxiv.org/abs/2407.03923">Paper</a>
          /
          <a href="https://github.com/Jho-Yonsei/CRiM-GS">Code</a>
          <!-- /
          <a href="data/bib/svl2024.txt">bib</a> -->
          <p></p>
          <p>
          <!-- We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling. -->
          We propose continous motion-aware blur kernel on 3D gaussian splatting utilizing 3D rigid transformation and neural ordinary differential function to reconstruct accurate 3D scene from blurry images with real-time rendering speed.
          </p>
        </td>
      </tr>

      <!-- <tr>
        <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cvf.jpg">
        </td>
        <td width="75%" valign="center">
          <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
          <br>
          <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
          <br>
          <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
          <br>
          <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
        </td>
      </tr>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cs188.jpg" alt="cs188">
        </td>
        <td width="75%" valign="center">
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
          <br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
          <br>
          <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
        </td>
      </tr>
      

      <tr>
        <td align="center" style="padding:20px;width:25%;vertical-align:middle">
          <heading>Basically <br> Blog Posts</heading>
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
          <br>
          <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
          <br>
          <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
        </td>
      </tr>
        -->	
    </tbody>
  </table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            This website's source code is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron's website</a>.
          </p>
          <p style="text-align:right;font-size:small;">
            Last updated July 2024.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  <!-- </td>
  </tr> -->
<!-- </table> -->
</body>

</html>
